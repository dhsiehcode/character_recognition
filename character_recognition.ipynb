{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1TrUiK42BTb_IVvHGb-H26re74q8S4Gla",
      "authorship_tag": "ABX9TyNwv+5MkClP1fPpMFjgi5Bi"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "PerrHqLqFicc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn import utils\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torchvision.transforms import v2\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import csv\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn as nn\n",
        "import torch.optim\n",
        "import torchvision.models as models\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torchmetrics import classification\n"
      ],
      "metadata": {
        "id": "Ctvjcjychzt6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/dennis_ocr/archive/mnistA-Z0-9.csv').astype('float32')\n"
      ],
      "metadata": {
        "id": "KCzi3AerQO4u"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_train_test(data):\n",
        "\n",
        "  data.rename(columns={'0':'label'}, inplace=True)\n",
        "\n",
        "  X = data.drop('label', axis = 1)\n",
        "  y = data['label']\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
        "\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "2YgPMqudgpHm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = get_train_test(data)"
      ],
      "metadata": {
        "id": "2dU4cc7SoOAw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_class_weights(y):\n",
        "\n",
        "  weights = compute_class_weight(class_weight = 'balanced', classes = y.value_counts().index, y = y)\n",
        "\n",
        "  return weights\n"
      ],
      "metadata": {
        "id": "WMgjNw_DI4WZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display(data, labels):\n",
        "\n",
        "  #X, y = utils.shuffle(data, labels)\n",
        "\n",
        "  plt.figure(figsize=(9,9))\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "\n",
        "    plt.imshow(X.iloc[i].values.reshape(28,28),interpolation='nearest', cmap='Greys')\n",
        "    ax.title.set_text(y[i])\n",
        "\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "55lRws-Hnbs8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_img(img, label):\n",
        "  plt.figure(figsize=(3,3))\n",
        "\n",
        "  ax = plt.imshow(img.values.reshape(28,28),interpolation='nearest', cmap='Greys')\n",
        "  print(label)\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "R6THgN9_316K"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Digits(Dataset):\n",
        "\n",
        "  def __init__(self, X, y, transform = None):\n",
        "    self.X = np.asarray(X)\n",
        "    self.X = self.X.reshape(self.X.shape[0], 28, 28).astype('float32')\n",
        "    #print(self.X.shape)\n",
        "    #print(self.X[0].shape)\n",
        "    self.X = torch.from_numpy(self.X).float()\n",
        "    self.y = np.asarray(y)\n",
        "    self.y = torch.from_numpy(self.y).long()\n",
        "    self.transform = transform\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.y)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    target = self.X[index]\n",
        "    #print(target.shape)\n",
        "    target.unsqueeze_(0)\n",
        "    target.repeat(3, 1, 1)\n",
        "    label = self.y[index]\n",
        "    if self.transform:\n",
        "      target = self.transform(target)\n",
        "    return target, label\n",
        "\n"
      ],
      "metadata": {
        "id": "1qe9m6dJsMKI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = v2.Compose([\n",
        "        v2.Resize((32, 32)),\n",
        "        v2.RandomRotation(10),\n",
        "        v2.RandomZoomOut( p = 0.2),\n",
        "        #v2.Random\n",
        "        v2.RandomResizedCrop(size=(32, 32), scale=(0.8, 1.2), ratio=(0.9, 1.1)),\n",
        "        #v2.ToTensor(),\n",
        "        v2.ToImage(),\n",
        "        v2.ToDtype(torch.float32, scale = True),\n",
        "        v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])"
      ],
      "metadata": {
        "id": "NF-Gbr5vzbPf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_transform = v2.Compose([\n",
        "    v2.Resize((32, 32)),\n",
        "    #v2.ToTensor(),\n",
        "    v2.ToImage(),\n",
        "    v2.ToDtype(torch.float32, scale = True),\n",
        "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "wclubI38wRMg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "training = Digits(X_train, y_train, transform = train_transform)\n",
        "testing = Digits(X_test, y_test, transform = test_transform)\n"
      ],
      "metadata": {
        "id": "VpV_zrr1sa_V"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dataloader = DataLoader(training, batch_size=128, shuffle=True)\n",
        "test_dataloader = DataLoader(testing, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "cF0wJ-kv1r82"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MetricMonitor:\n",
        "    def __init__(self, float_precision=3):\n",
        "        self.float_precision = float_precision\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.metrics = defaultdict(lambda: {\"val\": 0, \"count\": 0, \"avg\": 0})\n",
        "\n",
        "    def update(self, metric_name, val):\n",
        "        metric = self.metrics[metric_name]\n",
        "\n",
        "        metric[\"val\"] += val\n",
        "        metric[\"count\"] += 1\n",
        "        metric[\"avg\"] = metric[\"val\"] / metric[\"count\"]\n",
        "\n",
        "    def __str__(self):\n",
        "        return \" | \".join(\n",
        "            [\n",
        "                \"{metric_name}: {avg:.{float_precision}f}\".format(\n",
        "                    metric_name=metric_name, avg=metric[\"avg\"], float_precision=self.float_precision\n",
        "                )\n",
        "                for (metric_name, metric) in self.metrics.items()\n",
        "            ]\n",
        "        )\n",
        "\n"
      ],
      "metadata": {
        "id": "Gi_VhdrfTalJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "def calculate_accuracy(output, target):\n",
        "    predictions = torch.argmax(torch.softmax(output, dim = 1, dtype = None), dim = 1)\n",
        "    predictions = predictions.cpu().numpy()\n",
        "    target = target.cpu().numpy()\n",
        "\n",
        "    return (np.sum(target == predictions)/len(predictions))\n",
        "\n",
        "def train(train_loader, model, criterion, optimizer, epoch, params, train_accs):\n",
        "    torch.set_default_dtype(torch.float32)\n",
        "    metric_monitor = MetricMonitor()\n",
        "    model.train()\n",
        "    stream = tqdm(train_loader)\n",
        "    temp_accs = []\n",
        "    for i, (images, target) in enumerate(stream, start=1):\n",
        "        #images = images.to(params[\"device\"], non_blocking=True).float()\n",
        "        images = images.to(params[\"device\"], non_blocking=True)\n",
        "        #target = target.to(params[\"device\"], non_blocking=True).float().view(-1, 1)\n",
        "\n",
        "        #target = target.to(params[\"device\"], non_blocking=True).float()\n",
        "        target = target.to(params[\"device\"], non_blocking=True).float()\n",
        "        #print(target.long())\n",
        "        #print(images.shape)\n",
        "        output = model(images)\n",
        "        #print(output.shape)\n",
        "        #print(images)\n",
        "        #loss = criterion(output, target.long())\n",
        "        #type(target)\n",
        "        #target = target.type(torch.LongTensor)\n",
        "        type(target)\n",
        "        loss = criterion(output, target.long())\n",
        "        accuracy = calculate_accuracy(output, target)\n",
        "        temp_accs.append(accuracy)\n",
        "        metric_monitor.update(\"Loss\", loss.item())\n",
        "        metric_monitor.update(\"Accuracy\", accuracy)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        stream.set_description(\n",
        "            \"Epoch: {epoch}. Train.      {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\n",
        "        )\n",
        "\n",
        "    train_accs.append(np.mean(temp_accs))"
      ],
      "metadata": {
        "id": "_lqkqNBa2b88"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"model\": \"resnet50\",\n",
        "    #\"device\": \"cuda\", # for GPU\n",
        "    \"device\": \"cpu\", # for CPU\n",
        "    \"lr\": 0.0001,\n",
        "    \"batch_size\": 128,\n",
        "    \"num_workers\": 0,\n",
        "    \"epochs\": 10,\n",
        "}"
      ],
      "metadata": {
        "id": "jfKidhb4V8vU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model):\n",
        "  torch.save(model.state_dict(), '/content/drive/MyDrive/dennis_ocr/ocr.pt')\n"
      ],
      "metadata": {
        "id": "5cMP_JunjayB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = getattr(models, params[\"model\"])(pretrained=False, num_classes=36,)\n",
        "model = model.to(params[\"device\"])\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight = torch.from_numpy(get_class_weights(y_test)).float()).to(params[\"device\"])\n",
        "#criterion = nn.CrossEntropyLoss().to(params[\"device\"])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=params[\"lr\"], weight_decay=1e-5)\n",
        "\n",
        "\n",
        "#scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min')"
      ],
      "metadata": {
        "id": "tHWZLaLHV6kK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_default_dtype(torch.float32)\n",
        "\n",
        "train_accs = []\n",
        "\n",
        "for i in range(params['epochs']):\n",
        "  train(train_dataloader,  model, criterion, optimizer, i, params, train_accs)\n",
        "  if train_accs[i] > 0.95 or i == (params['epochs'] - 1):\n",
        "    save_model(model)\n",
        "    break"
      ],
      "metadata": {
        "id": "e-pNRm4fXyvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## testing\n",
        "def test():\n",
        "\n",
        "  model.load_state_dict(torch.load('/content/drive/MyDrive/dennis_ocr/ocr.pt', map_location=torch.device('cpu')))\n",
        "  model.eval()\n",
        "  predicted_labels = []\n",
        "  actual_labels = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for images, labels in test_dataloader:\n",
        "      images = images.to(params[\"device\"], non_blocking=True)\n",
        "      output = model(images)\n",
        "\n",
        "      predictions = torch.argmax(torch.softmax(output, dim = 1, dtype = None), dim = 1)\n",
        "      predictions = predictions.cpu().numpy()\n",
        "\n",
        "      for l in labels:\n",
        "\n",
        "        actual_labels.append(l)\n",
        "\n",
        "      for p in predictions:\n",
        "\n",
        "        predicted_labels.append(p)\n",
        "\n",
        "      #break\n",
        "  return predicted_labels, actual_labels\n"
      ],
      "metadata": {
        "id": "q5iaBUO_znd9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_for_metric(weights_path):\n",
        "  model.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu')))\n",
        "  model.eval()\n",
        "  preds = []\n",
        "  actual = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for images, labels in test_dataloader:\n",
        "      images = images.to(params[\"device\"], non_blocking=True)\n",
        "      output = model(images)\n",
        "\n",
        "      #print(torch.softmax(output, dim = 1, dtype = None).shape)\n",
        "      preds.extend(torch.softmax(output, dim = 1, dtype = None).cpu().numpy())\n",
        "      #print(len(preds))\n",
        "\n",
        "      for label in labels:\n",
        "        actual.append(label)\n",
        "\n",
        "\n",
        "  return np.asarray(preds), np.asarray(actual)\n"
      ],
      "metadata": {
        "id": "AvgStMDtR_4G"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds, actual = test_for_metric('/content/drive/MyDrive/dennis_ocr/ocr.pt')"
      ],
      "metadata": {
        "id": "P1R9rloInCFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roc = classification.MulticlassROC(36)\n",
        "fpr, tpr, thresholds = roc(torch.from_numpy(preds), torch.from_numpy(actual))"
      ],
      "metadata": {
        "id": "98ohTsSgFsVU"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = roc.plot(score = True)\n",
        "ax.legend(loc = 'lower center', ncols = 6)\n",
        "fig.set_size_inches(8,8)\n"
      ],
      "metadata": {
        "id": "go-W08aeNv7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig.savefig('/content/drive/MyDrive/dennis_ocr/roc_plot')"
      ],
      "metadata": {
        "id": "MpQz_DulZZGU"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi_accs = classification.MulticlassAccuracy(num_classes=36, average = 'none')\n",
        "multi_accs(torch.from_numpy(preds), torch.from_numpy(actual))"
      ],
      "metadata": {
        "id": "XFR7Ve9DF0Id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig, ax = multi_accs.plot()\n",
        "ax.legend(loc=\"lower center\", ncols = 3)\n",
        "fig.set_size_inches(8,8)\n"
      ],
      "metadata": {
        "id": "WUoQXy4ZkmH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig.savefig('/content/drive/MyDrive/dennis_ocr/multi_accs')"
      ],
      "metadata": {
        "id": "Qep7OvIXkpV3"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confmat = classification.MulticlassConfusionMatrix(num_classes=36)\n",
        "confmat(torch.from_numpy(preds), torch.from_numpy(actual))"
      ],
      "metadata": {
        "id": "vA1F2P5ARbWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig, ax = confmat.plot()\n",
        "fig.set_size_inches(16, 16)\n",
        "\n"
      ],
      "metadata": {
        "id": "9xLLb2wVRlBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig.savefig('/content/drive/MyDrive/dennis_ocr/confmat')"
      ],
      "metadata": {
        "id": "jjmfni8xpU6T"
      },
      "execution_count": 79,
      "outputs": []
    }
  ]
}